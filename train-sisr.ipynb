{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required functions\n",
    "Run at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, glob, warnings, os\n",
    "import argparse\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, utils\n",
    "import torchvision\n",
    "from skimage import exposure, color, io, img_as_float, img_as_ubyte\n",
    "from skimage.util import view_as_windows\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "import datasets_sisr as data\n",
    "import srmodels as models\n",
    "\n",
    "def data_loader(model_config, csv='train'):\n",
    "    if csv=='train':\n",
    "        transformed_dataset = data.Pair_Dataset(csv_file=data.compress_csv_path(csv),\n",
    "                                                   transform=data.Compose([\n",
    "                                                       data.Recale(model_config[\"resolution\"]),\n",
    "                                                       data.ToTensor()\n",
    "                                               ]))\n",
    "        dataloader = DataLoader(transformed_dataset, batch_size=model_config[\"batch-size\"], shuffle=True, num_workers=model_config[\"threads\"])\n",
    "    if csv=='valid':\n",
    "        transformed_dataset = data.Pair_Dataset(csv_file=data.compress_csv_path(csv),\n",
    "                                                   transform=data.Compose([\n",
    "                                                       data.Recale(model_config[\"resolution\"]),\n",
    "                                                       data.ToTensor()\n",
    "                                               ]))\n",
    "        dataloader = DataLoader(transformed_dataset, batch_size=model_config[\"batch-size\"], shuffle=False, num_workers=model_config[\"threads\"])\n",
    "    return dataloader\n",
    "\n",
    "def train(model_config, epoch, run, generator, dataloader, criterion, optimizer):\n",
    "    epoch_loss = 0\n",
    "    generator.train()\n",
    "    device = next(generator.parameters()).device\n",
    "    for iteration, batch in enumerate(dataloader):\n",
    "        img_input = Variable(batch['input'].float().to(device), requires_grad=False)\n",
    "        img_target = Variable(batch['output'].float().to(device), requires_grad=False)   \n",
    "        optimizer.zero_grad()       \n",
    "        img_output = generator(img_input)\n",
    "        loss = criterion(img_output, img_target)               \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss = epoch_loss + loss.item()\n",
    "        \n",
    "        sys.stdout.write('\\r[%d/%d][%d/%d] Generator_L1_Loss: %.4f' \n",
    "                             % (epoch, model_config[\"epochs\"], iteration, len(dataloader), loss.item()))\n",
    "    print(\"\\n ===> Epoch {} Complete: Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(dataloader)))\n",
    "    \n",
    "    g_path = os.path.join('weights', run, 'generator.pth')\n",
    "    os.makedirs(os.path.join('weights', run), exist_ok=True)\n",
    "    torch.save(generator.state_dict(), g_path)\n",
    "\n",
    "def test(generator, dataloader, criterion):\n",
    "    device = next(generator.parameters()).device\n",
    "    with torch.no_grad():\n",
    "        epoch_loss = 0\n",
    "        generator.eval()\n",
    "        for iteration, batch in enumerate(dataloader):\n",
    "            img_input = Variable(batch['input'].float().to(device), requires_grad=False)\n",
    "            img_target = Variable(batch['output'].float().to(device), requires_grad=False)\n",
    "            img_output = generator(img_input)\n",
    "            epoch_loss = epoch_loss + criterion(img_output, img_target).item()\n",
    "        return epoch_loss / len(dataloader)\n",
    "    \n",
    "def print_output(trained_model, dataloader_valid):\n",
    "    device = next(trained_model.parameters()).device\n",
    "    trained_model.eval()\n",
    "    os.makedirs('print-sr', exist_ok=True)\n",
    "    with torch.no_grad():      \n",
    "        print(\"===> 8x:\")\n",
    "        for iteration, batch in enumerate(dataloader_valid):     \n",
    "            input, target = batch['input'].to(device), batch['output'].to(device)\n",
    "            imgs_input = Variable(input.type(Tensor))\n",
    "            prediction = trained_model(imgs_input)\n",
    "            target = target.float()    \n",
    "            imgs_input = imgs_input[:, :, :, :]\n",
    "            prediction = prediction[:, :, :, :]\n",
    "            target = target[:, :, :, :]\n",
    "            plt.figure(figsize=(20, 6))\n",
    "            grid = utils.make_grid(imgs_input).cpu()\n",
    "            utils.save_image(grid, 'print-sr/input.tif')\n",
    "            input_downsampled = grid.numpy().transpose((1, 2, 0))\n",
    "            plt.imshow(input_downsampled, interpolation='bicubic')\n",
    "            plt.axis('off') \n",
    "            plt.figure(figsize=(20, 6))\n",
    "            grid = utils.make_grid(prediction).cpu()\n",
    "            utils.save_image(grid, 'print-sr/output.tif')\n",
    "            prediction = np.clip(grid.numpy().transpose((1, 2, 0)), 0, 1)\n",
    "            plt.imshow(prediction, interpolation='bicubic')\n",
    "            plt.axis('off')    \n",
    "            plt.figure(figsize=(20, 6))\n",
    "            grid = utils.make_grid(target).cpu()\n",
    "            utils.save_image(grid, 'print-sr/target.tif')\n",
    "            target = grid.numpy().transpose((1, 2, 0))\n",
    "            plt.imshow(target, interpolation='bicubic')\n",
    "            plt.axis('off')                                  \n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and model configurations\n",
    "Run after adjustment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"image-channel\" : 1,\n",
    "    \"batch-size\" : 32,\n",
    "    \"epochs\" : 100,\n",
    "    \"learning-rate\" : 0.0002,\n",
    "    \"resolution\" : 512,\n",
    "    \"run-from\" : None,\n",
    "    \"cnn-base-channel\" : 8,\n",
    "    \"normalization\" : \"batch\",\n",
    "    \"gpu\" : True,\n",
    "    \"threads\" : 4,\n",
    "    \"test-interval\" : 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview examples from the dataset\n",
    "Wait for images to be printed in a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_config[\"gpu\"]:\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "data.generate_compress_csv()\n",
    "valid_dataset = data_loader(model_config, 'valid')\n",
    "data.show_patch(valid_dataset, 0)\n",
    "generator = models.Generator(model_config[\"image-channel\"], base_channel=model_config[\"cnn-base-channel\"], norm=model_config[\"normalization\"])\n",
    "generator.to(device);\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(generator.parameters(), lr=model_config[\"learning-rate\"])\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, model_config[\"epochs\"], model_config[\"learning-rate\"]*0.1)\n",
    "if model_config[\"run-from\"] is not None:\n",
    "    generator.load_state_dict(torch.load(os.path.join('model-weights', model_config[\"run-from\"], 'model-sisr.pth')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 'sisr' + '-' + datetime.now().strftime(\"%Y-%m-%d--%H-%M-%S\")\n",
    "train_dataset = data_loader(model_config, 'train')\n",
    "for epoch in range(model_config[\"epochs\"]):\n",
    "    train(model_config, epoch, run, generator, train_dataset, criterion, optimizer)   \n",
    "    scheduler.step()\n",
    "    if epoch % model_config[\"test-interval\"] == 0:\n",
    "        test_loss = test(generator, valid_dataset, criterion)\n",
    "        print('\\r>>>> [{}/{}] test_loss: {}'.format(epoch, model_config[\"epochs\"], test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_output(generator, valid_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
