{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from skimage import img_as_uint\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from denoiser import Denoiser\n",
    "from lsm_utils import normalize_16bit_images, compute_norm_range\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data \n",
    "- SHG samples\n",
    "- load model config data from yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data\\*.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n"
     ]
    }
   ],
   "source": [
    "def sandbox_compute_norm_range(fname, percentiles=(0, 100), sample_r=0.1):\n",
    "    max_val = []\n",
    "    min_val = []\n",
    "    fail_names = []\n",
    "    try:\n",
    "        img = img_as_uint(io.imread(fname))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(fname)\n",
    "        fail_names.append(fname)\n",
    "    max_val.append(np.percentile(img, percentiles[1]))\n",
    "    min_val.append(np.percentile(img, percentiles[0]))\n",
    "    max_val: float | np.ndarray = np.percentile(np.array(max_val), 98)\n",
    "    min_val: float | np.ndarray = np.percentile(np.array(min_val), 2)\n",
    "    \n",
    "    return min_val, max_val, fail_names\n",
    "\n",
    "# vmin, vmax, fail_names = sandbox_compute_norm_range('sample_data/1B_C1.tif', percentiles=(1, 99.5), sample_r=0.05)\n",
    "vmin, vmax, fail_names = compute_norm_range('sample_data', ext='tif', percentiles=(1, 99.5), sample_r=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open(\"model_config.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "config['dataset'] = 'sample_data'\n",
    "config['norm-range'] = [int(vmin), int(vmax)]\n",
    "config['threads'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model instance\n",
    "* Create instance of denoiser with new config data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\aarus/.cache\\torch\\hub\\mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    }
   ],
   "source": [
    "# Set background screening to false to allow PB522-14-MAX-Fused.tif to be accepted\n",
    "denoiser = Denoiser(config, screen_bg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 5.39 GiB. GPU 0 has a total capacty of 6.00 GiB of which 0 bytes is free. Of the allocated memory 10.78 GiB is allocated by PyTorch, and 105.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aarus\\College\\Senior\\loci-lab\\lsm-run-time-enhancement\\denoise_sandbox.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aarus/College/Senior/loci-lab/lsm-run-time-enhancement/denoise_sandbox.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Denoiser only works on grayscale images\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aarus/College/Senior/loci-lab/lsm-run-time-enhancement/denoise_sandbox.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m denoiser\u001b[39m.\u001b[39;49mdenoise()\n",
      "File \u001b[1;32mc:\\Users\\aarus\\College\\Senior\\loci-lab\\lsm-run-time-enhancement\\denoiser.py:180\u001b[0m, in \u001b[0;36mDenoiser.denoise\u001b[1;34m(self, sampling, sample_rate, batch_size)\u001b[0m\n\u001b[0;32m    178\u001b[0m out_tensor \u001b[39m=\u001b[39m img_tensor \u001b[39m*\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    179\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(iterations):\n\u001b[1;32m--> 180\u001b[0m     drop_mask \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mdropout(torch\u001b[39m.\u001b[39;49mones(img_hyper_tensor\u001b[39m.\u001b[39;49mshape, requires_grad\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\u001b[39m.\u001b[39;49mto(device), p\u001b[39m=\u001b[39;49mp, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m*\u001b[39m(\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mp) \u001b[39m# p percent zero, keep\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     pad_mask \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mdrop_mask) \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mones(img_hyper_tensor\u001b[39m.\u001b[39mshape, device\u001b[39m=\u001b[39mdevice, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32) \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mmean(img_hyper_tensor, (\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m), keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mexpand_as(img_hyper_tensor)\n\u001b[0;32m    182\u001b[0m     spotted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmul(img_hyper_tensor, drop_mask) \u001b[39m+\u001b[39m pad_mask\n",
      "File \u001b[1;32mc:\\Users\\aarus\\miniforge3\\envs\\lsm-run-time-enhancement\\Lib\\site-packages\\torch\\nn\\functional.py:1266\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1264\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[0;32m   1265\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[39m{\u001b[39;00mp\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1266\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49mdropout_(\u001b[39minput\u001b[39;49m, p, training) \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m _VF\u001b[39m.\u001b[39mdropout(\u001b[39minput\u001b[39m, p, training)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 5.39 GiB. GPU 0 has a total capacty of 6.00 GiB of which 0 bytes is free. Of the allocated memory 10.78 GiB is allocated by PyTorch, and 105.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Denoiser only works on grayscale images\n",
    "denoiser.denoise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsm-run-time-enhancement",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
